import streamlit as st
import os
from dotenv import load_dotenv
from groq import Groq
from openai import OpenAI
import random

# ‡πÇ‡∏´‡∏•‡∏î API Key
load_dotenv()
GROQ_KEY = os.getenv("GROQ_API_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

groq_client = Groq(api_key=GROQ_KEY)
openai_client = OpenAI(api_key=OPENAI_KEY)

# -------------------------------
# Model list
MODELS = {
    "üß† OpenAI GPT (gpt-4o-mini)": {
        "provider": "openai",
        "id": "gpt-4o-mini",
    },
    "ü¶ô LLaMA 3.1 8B Instant": {
        "provider": "groq",
        "id": "llama-3.1-8b-instant",
    },
    "ü¶ô LLaMA 3.3 70B Versatile": {
        "provider": "groq",
        "id": "llama-3.3-70b-versatile",
    },
    "ü¶ô Allam 2 7B": {
        "provider": "groq",
        "id": "allam-2-7b",
    },
    "ü¶ô DeepSeek R1 Distill 70B": {
        "provider": "groq",
        "id": "deepseek-r1-distill-llama-70b",
    },
    "üß™ Gemma 2 9B": {
        "provider": "groq",
        "id": "gemma2-9b-it",
    },
    "üåø Groq Compound": {
        "provider": "groq",
        "id": "groq/compound",
    },
    "üåø Groq Compound Mini": {
        "provider": "groq",
        "id": "groq/compound-mini",
    },
    "ü¶ô LLaMA 4 Maverick 17B": {
        "provider": "groq",
        "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
    },
    "ü¶ô LLaMA 4 Scout 17B": {
        "provider": "groq",
        "id": "meta-llama/llama-4-scout-17b-16e-instruct",
    },
    "ü¶ô LLaMA Guard 4 12B": {
        "provider": "groq",
        "id": "meta-llama/llama-guard-4-12b",
    },
    "üõ°Ô∏è Prompt Guard 22M": {
        "provider": "groq",
        "id": "meta-llama/llama-prompt-guard-2-22m",
    },
    "üõ°Ô∏è Prompt Guard 86M": {
        "provider": "groq",
        "id": "meta-llama/llama-prompt-guard-2-86m",
    },
    "üåô Moonshot Kimi K2": {
        "provider": "groq",
        "id": "moonshotai/kimi-k2-instruct",
    },
    "üåô Moonshot Kimi K2 (0905)": {
        "provider": "groq",
        "id": "moonshotai/kimi-k2-instruct-0905",
    },
    "üß† GPT OSS 120B": {
        "provider": "groq",
        "id": "openai/gpt-oss-120b",
    },
    "üß† GPT OSS 20B": {
        "provider": "groq",
        "id": "openai/gpt-oss-20b",
    },
    "üó£Ô∏è PlayAI TTS": {
        "provider": "groq",
        "id": "playai-tts",
    },
    "üó£Ô∏è PlayAI TTS Arabic": {
        "provider": "groq",
        "id": "playai-tts-arabic",
    },
    "üß† Qwen 3 32B": {
        "provider": "groq",
        "id": "qwen/qwen3-32b",
    },
}

# -------------------------------
# ‡πÄ‡∏°‡∏ô‡∏π‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
basic_menu = [
    "‡∏Ç‡πâ‡∏≤‡∏ß‡∏Å‡∏∞‡πÄ‡∏û‡∏£‡∏≤‡πÑ‡∏Ç‡πà‡∏î‡∏≤‡∏ß üç≥",
    "‡∏Å‡πã‡∏ß‡∏¢‡πÄ‡∏ï‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏£‡∏∑‡∏≠ ü•¢",
    "‡∏™‡πâ‡∏°‡∏ï‡∏≥ ‡πÑ‡∏Å‡πà‡∏¢‡πà‡∏≤‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß üêî",
    "‡∏Ç‡πâ‡∏≤‡∏ß‡∏ú‡∏±‡∏î‡∏Å‡∏∏‡πâ‡∏á üç§",
    "‡∏ú‡∏±‡∏î‡πÑ‡∏ó‡∏¢ ü•ú",
    "‡∏ä‡∏≤‡∏ö‡∏π üç≤",
    "‡∏´‡∏°‡∏π‡∏Å‡∏£‡∏∞‡∏ó‡∏∞ üê∑üî•",
    "‡∏£‡∏≤‡πÄ‡∏°‡∏á üçú",
    "‡∏ã‡∏π‡∏ä‡∏¥ üç£",
    "‡∏û‡∏¥‡∏ã‡∏ã‡πà‡∏≤ üçï"
]

# -------------------------------
# UI
st.set_page_config(page_title="FoodBot üçú", page_icon="üçΩÔ∏è")
st.title("ü§ñ FoodBot ‚Äî ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ ‡∏ö‡∏≠‡∏Å‡∏â‡∏±‡∏ô‡∏™‡∏¥!")

# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
selected_model = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI", list(MODELS.keys()))
model_info = MODELS[selected_model]

user_input = st.text_input("‡∏Ñ‡∏∏‡∏ì:", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡πÅ‡∏ã‡∏ö‡πÜ, ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏ö‡∏≤‡πÜ, ...")

if st.button("‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ üçΩÔ∏è"):
    suggestion = random.choice(basic_menu)
    st.success(f"ü•¢ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏•‡∏≠‡∏á‡∏Å‡∏¥‡∏ô **{suggestion}** ‡∏î‡∏π‡πÑ‡∏´‡∏°?")

if st.button("‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏¥‡∏î‡πÄ‡∏°‡∏ô‡∏π üß†"):
    if user_input.strip():
        with st.spinner(f"Thinking {selected_model}..."):
            prompt = f"Suggest one food menu for '{user_input}'"
            if model_info["provider"] == "openai":
                response = openai_client.chat.completions.create(
                    model=model_info["id"],
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=50,
                    temperature=0.4
                )
                ai_suggestion = response.choices[0].message.content
            else:
                response = groq_client.chat.completions.create(
                    model=model_info["id"],
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=50,
                    temperature=0.4
                )
                ai_suggestion = response.choices[0].message.content

        st.success(f"üçú {ai_suggestion}")
    else:
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö üòä")
