import streamlit as st
import os
from dotenv import load_dotenv
from litellm import completion
from sentence_transformers import SentenceTransformer, util
import random
import json

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ---

# Load API Key
# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡∏ß‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ key ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .env ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà GROQ_API_KEY="your-key" ‡πÅ‡∏•‡∏∞ OPENAI_API_KEY="your-key"
try:
    load_dotenv()
    GROQ_KEY = os.getenv("GROQ_API_KEY")
    OPENAI_KEY = os.getenv("OPENAI_API_KEY")

    # Setting keys by environment
    os.environ["GROQ_API_KEY"] = GROQ_KEY
    os.environ["OPENAI_API_KEY"] = OPENAI_KEY
except Exception as e:
    print(f"Could not load .env file: {e}")
    GROQ_KEY = None
    OPENAI_KEY = None


# Model list
MODELS = {
    "üß† OpenAI GPT (gpt-4o-mini)": {
        "id": "gpt-4o-mini",
        "api_key": OPENAI_KEY,
    },
    "ü¶ô LLaMA 3.1 8B Instant": {
        "id": "groq/llama-3.1-8b-instant",
        "api_key": GROQ_KEY,
    },
    "ü¶ô LLaMA 3.3 70B Versatile": {
        "id": "groq/llama-3.3-70b-versatile",
        "api_key": GROQ_KEY,
    },
}

# --- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ---
@st.cache_resource
def load_rag_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

rag_model = load_rag_model()

# --- ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏°‡∏ô‡∏π‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå txt ---
@st.cache_data
def load_menu_from_txt(file_path="menu.txt"):
    menu_knowledge = {}
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                if ":" in line:
                    name, desc = line.strip().split(":", 1)
                    menu_knowledge[name.strip()] = desc.strip()
    except FileNotFoundError:
        st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {file_path}")
    return menu_knowledge

menu_knowledge = load_menu_from_txt()

# --- ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ---
@st.cache_data
def build_menu_embeddings(menu_knowledge):
    return {name: rag_model.encode(desc, normalize_embeddings=True)
            for name, desc in menu_knowledge.items()}

menu_embeddings = build_menu_embeddings(menu_knowledge)

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π‡πÅ‡∏ö‡∏ö RAG ---
def rag_random_menu(query: str = "‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ", top_k: int = 10):
    """‡πÉ‡∏ä‡πâ Retrieval-Augmented Generation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå txt"""
    if not menu_embeddings:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏°‡∏ô‡∏π‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
    
    query_emb = rag_model.encode(query, normalize_embeddings=True)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity
    sims = {name: float(util.dot_score(query_emb, emb))
            for name, emb in menu_embeddings.items()}

    # ‡πÄ‡∏≠‡∏≤ top-k ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    top_items = sorted(sims.items(), key=lambda x: x[1], reverse=True)[:top_k]

    # ‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å top-k
    selected_menu, score = random.choice(top_items)
    desc = menu_knowledge[selected_menu]

    return f"ü•¢ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏•‡∏≠‡∏á‡∏Å‡∏¥‡∏ô **{selected_menu}** ‡∏î‡∏π‡πÑ‡∏´‡∏°?\n\n{desc}\n(‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á {score:.2f})"


# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Function Calling ---
# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON
try:
    with open('foodlist.json', 'r', encoding='utf-8') as f:
        food_data = json.load(f)
except FileNotFoundError:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå foodlist.json ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô")
    food_data = []

# 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ)
def search_menu(spicy: bool = None, seafood: bool = None, meat: str = None, cuisine: str = None, green_level: str = None, max_calories: int = None):
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    
    Args:
        spicy (bool, optional): ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏£‡∏™‡πÄ‡∏ú‡πá‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà.
        seafood (bool, optional): ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏∞‡πÄ‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà.
        meat (str, optional): ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô 'pork', 'chicken', 'shrimp'.
        cuisine (str, optional): ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô 'thai', 'japanese', 'healthy'.
        green_level (str, optional): ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏ô‡∏°‡∏±‡∏á‡∏™‡∏ß‡∏¥‡∏£‡∏±‡∏ï‡∏¥ 'vegetarian' ‡∏´‡∏£‡∏∑‡∏≠ 'vegan'.
        max_calories (int, optional): ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î.

    Returns:
        list: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç
    """
    results = food_data
    
    if spicy is not None:
        results = [item for item in results if item['spicy'] == spicy]
    if seafood is not None:
        results = [item for item in results if item['seafood'] == seafood]
    if meat:
        results = [item for item in results if meat.lower() in item['meat']]
    if cuisine:
        results = [item for item in results if item['cuisine'].lower() == cuisine.lower()]
    if green_level:
        results = [item for item in results if item['green_level'].lower() == green_level.lower()]
    if max_calories is not None:
        results = [item for item in results if item['avg_calories'] <= max_calories]
        
    if not results:
        return ["‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏î‡∏π‡∏ô‡∏∞"]
        
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà
    return [f"{item['name']} ({item['avg_calories']} kcal)" for item in results]

# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Schema ‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (Tool Definition)
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_menu",
            "description": "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏™‡∏±‡∏ï‡∏ß‡πå, ‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏´‡∏≤‡∏£",
            "parameters": {
                "type": "object",
                "properties": {
                    "spicy": {"type": "boolean", "description": "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏£‡∏™‡πÄ‡∏ú‡πá‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"},
                    "seafood": {"type": "boolean", "description": "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏∞‡πÄ‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"},
                    "meat": {"type": "string", "description": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô pork, chicken, shrimp"},
                    "cuisine": {"type": "string", "description": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô thai, japanese, healthy"},
                    "green_level": {"type": "string", "enum": ["vegetarian", "vegan"], "description": "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏≤‡∏ô‡∏°‡∏±‡∏á‡∏™‡∏ß‡∏¥‡∏£‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏µ‡πÅ‡∏Å‡∏ô"},
                    "max_calories": {"type": "number", "description": "‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡πÅ‡∏Ñ‡∏•‡∏≠‡∏£‡∏µ‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô"}
                },
                "required": [], # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å parameter ‡πÄ‡∏õ‡πá‡∏ô optional
            },
        }
    }
]


# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á UI (Streamlit) ---

st.set_page_config(page_title="FoodBot Kin-Arai-Dee üçú", page_icon="üçΩÔ∏è")
st.title("üçΩ Kin-Arai-Dee FoodBot")
st.subheader("‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ ‡∏ö‡∏≠‡∏Å AI ‡∏™‡∏¥!")

# RAG random
if st.button("üçΩÔ∏è ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå txt"):
    with st.spinner("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏°‡∏ô‡∏π‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå..."):
        suggestion = rag_random_menu()
        st.success(suggestion)

st.divider()

st.subheader("ü§ñ ‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏¥‡∏î‡πÄ‡∏°‡∏ô‡∏π (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)")
selected_model_name = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI", list(MODELS.keys()))
model_info = MODELS[selected_model_name]

user_input = st.text_input("‡∏Ñ‡∏∏‡∏ì:", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡πÅ‡∏ã‡πà‡∏ö‡πÜ ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ó‡∏∞‡πÄ‡∏•, ‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏ô‡∏Ñ‡∏•‡∏µ‡∏ô‡πÜ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢, ...")

if st.button("üß† ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏Ñ‡∏¥‡∏î"):
    if not user_input.strip():
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏¥‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö üòä")
    elif not model_info.get("api_key"):
        st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {selected_model_name} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")
    else:
        with st.spinner(f"ü§ñ {selected_model_name} ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏°‡∏ô‡∏π‡πÉ‡∏´‡πâ‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ô‡∏∞..."):
            try:
                # --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Function Calling ---
                
                # 1. ‡∏™‡πà‡∏á request ‡πÅ‡∏£‡∏Å‡πÉ‡∏´‡πâ AI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö tools ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏°‡∏µ
                messages = [{"role": "user", "content": user_input}]
                
                first_response = completion(
                    model=model_info["id"],
                    messages=messages,
                    tools=tools,
                    tool_choice="auto", # ‡πÉ‡∏´‡πâ AI ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ function ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    api_key=model_info["api_key"]
                )
                
                response_message = first_response.choices[0].message
                messages.append(response_message) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡∏≠‡∏á AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô history

                # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ AI ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if response_message.tool_calls:
                    st.info("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏ô‡∏π...")
                    
                    # 3. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà AI ‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠
                    available_functions = {"search_menu": search_menu}
                    tool_call = response_message.tool_calls[0]
                    function_name = tool_call.function.name
                    function_to_call = available_functions[function_name]
                    function_args = json.loads(tool_call.function.arguments)
                    
                    # Call the local function with arguments provided by the model
                    function_response = function_to_call(**function_args)
                    
                    # 4. ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI
                    messages.append(
                        {
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": json.dumps(function_response, ensure_ascii=False),
                        }
                    )
                    
                    # 5. ‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                    st.info("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
                    final_response = completion(
                        model=model_info["id"],
                        messages=messages,
                        api_key=model_info["api_key"]
                    )
                    ai_suggestion = final_response.choices[0].message.content
                else:
                    # ‡∏ñ‡πâ‡∏≤ AI ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ‡∏Å‡πá‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
                    ai_suggestion = response_message.content

                st.success(f"üçú **AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡πà‡∏≤:**\n\n{ai_suggestion}")

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö AI: {e}")
